{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Automatic_Ticket_processing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNO/lQIEM2d9i5IkjBVpMjs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kawadeshailesh1981/Capstone-NLP-Automatic_Ticket_Assignment/blob/master/Automatic_Ticket_processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfGIPep1AN5X",
        "colab_type": "text"
      },
      "source": [
        "# Pre-Processing, Data Visualization and EDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLwN04stAJcT",
        "colab_type": "text"
      },
      "source": [
        "Exploring the given Data files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlwMiNtDAZkX",
        "colab_type": "text"
      },
      "source": [
        "Understanding the structure of data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekfMBTIIAZ4N",
        "colab_type": "text"
      },
      "source": [
        "Missing points in data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGFWI3VbAaBF",
        "colab_type": "text"
      },
      "source": [
        "Finding inconsistencies in the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeZGUC_UAaLf",
        "colab_type": "text"
      },
      "source": [
        "Visualizing different patterns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQHI0yhJAx1R",
        "colab_type": "text"
      },
      "source": [
        "Visualizing different text features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTnQLx1YA5F5",
        "colab_type": "text"
      },
      "source": [
        "Dealing with missing values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBRgYUffA5Jf",
        "colab_type": "text"
      },
      "source": [
        "Text preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lPPZIFAA5Py",
        "colab_type": "text"
      },
      "source": [
        "Creating word vocabulary from the corpus of report text data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmBM-8quA5ag",
        "colab_type": "text"
      },
      "source": [
        "Creating tokens as required"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-_Bd_ZQA5dz",
        "colab_type": "text"
      },
      "source": [
        "## Model Building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vs1F4UzvA5h-",
        "colab_type": "text"
      },
      "source": [
        "Building a model architecture which can classify."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6Vpp0WYA5m2",
        "colab_type": "text"
      },
      "source": [
        "Trying different model architectures by researching state of the art for similar tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsD9kp78A5ru",
        "colab_type": "text"
      },
      "source": [
        "Train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiC3R-voA5p7",
        "colab_type": "text"
      },
      "source": [
        "To deal with large training time, save the weights so that you can use them when training the\n",
        "model for the second time without starting from scratch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a63mkAAbA5Y4",
        "colab_type": "text"
      },
      "source": [
        "# Test the Model, Fine-tuning and Repeat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RM7LJ66tA5Wl",
        "colab_type": "text"
      },
      "source": [
        "Test the model and report as per evaluation metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqIKXerwBenH",
        "colab_type": "text"
      },
      "source": [
        "Try different models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dL8xfcMABe2R",
        "colab_type": "text"
      },
      "source": [
        "Try different evaluation metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SURDPoFKA5Nn",
        "colab_type": "text"
      },
      "source": [
        "Set different hyper parameters, by trying different optimizers, loss functions, epochs, learning\n",
        "rate, batch size, checkpointing, early stopping etc..for these models to fine-tune them"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjCMdzoHBq_y",
        "colab_type": "text"
      },
      "source": [
        "Report evaluation metrics for these models along with your observation on how changing\n",
        "different hyper parameters leads to change in the final evaluation metric."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtUhskbWBo-l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}